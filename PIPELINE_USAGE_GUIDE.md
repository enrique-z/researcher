# Pipeline Usage Guide: Researcher + Sakana Integration

## ğŸ¯ **Your Current Problem â†’ Our Solution**

**Your Current Workflow (Pain Points):**
1. âŒ Generate experiments â†’ Send to Researcher â†’ Get beautiful 128-page papers
2. âŒ Send papers to Sakana â†’ **Manual testing and corrections required**
3. âŒ **Continuous forensic anti-synthetic data detection needed**
4. âŒ **Repeat manual corrections until Sakana works**

**Our Automated Solution:**
1. âœ… **Pre-validate experiments** â†’ Automated corrections â†’ **Only send good experiments to Researcher**
2. âœ… **Automated synthetic data detection** â†’ **Automated replacement with real data**
3. âœ… **Enhanced Researcher generation** with validated context â†’ **Higher quality papers**
4. âœ… **Final quality assurance** â†’ **Ready-to-publish super papers**

---

## ğŸš¦ **Three Pipeline Flow Options**

### **Option 1: Sequential Flow (Your Current Process)**
```
Experiment â†’ Researcher â†’ 128-page Paper â†’ Sakana â†’ Manual Corrections â†’ Repeat
```
**âš ï¸ Problem:** Wastes effort generating papers that fail validation (your current pain)

### **Option 2: Parallel Flow** 
```
Experiment â†’ [Researcher + Sakana in parallel] â†’ Merge Results
```
**âš ï¸ Problem:** Complex merging, potential conflicts

### **Option 3: Pre-Validation Gateway (RECOMMENDED)** â­
```
Experiment â†’ Sakana Pre-Screen â†’ [PASS: Enhanced Researcher] â†’ Super Paper
                               â†’ [FAIL: Reject before wasting effort]
```
**âœ… Solution:** Prevents wasted effort, automates your manual corrections

---

## ğŸ”§ **Recommended Pipeline: Pre-Validation Gateway**

This automates your manual correction workflow and implements the Sakana Principle as a **quality gate**.

### **Stage 1: Automated Pre-Screening (Replaces Manual Testing)**

```python
from ai_researcher.pipeline import IntegrationPipeline

# Initialize pipeline with your GLENS data
pipeline = IntegrationPipeline(
    glens_data_path="/Users/apple/code/ai-s-plus/data/glens",
    enable_pre_screening=True  # Pre-validation gateway
)

# Your experiment proposal
experiment = {
    "id": "sai_composition_v2",
    "title": "SAI Particle Chemical Composition Analysis", 
    "methodology": "Multi-domain validation using GLENS ensemble data",
    "parameters": {
        "h2so4_concentration_percent": 75.0,
        "temperature_k": 220.0,
        "ensemble_size": 20
    }
}

# Process through pipeline
result = pipeline.process_experiment(experiment)
```

### **What Happens Automatically:**

#### **ğŸ” Forensic Synthetic Data Detection (Automates Your Manual Process)**
- âœ… **Detects unrealistic parameters** (e.g., perfect values like 1.0, 10.0)
- âœ… **Identifies missing natural variability** (red flag for synthetic data)
- âœ… **Finds unit inconsistencies** (common in generated data)
- âœ… **Discovers perfect mathematical relationships** (unlikely in real data)

#### **ğŸ”„ Automated Corrections (Replaces Manual Changes)**
- âœ… **Replaces synthetic data with authentic GLENS values**
- âœ… **Adds natural variability indicators**
- âœ… **Fixes unit inconsistencies**
- âœ… **Adjusts unrealistic parameters to physical ranges**

#### **âœ… Sakana Principle Validation**
- âœ… **Domain-specific validation** (chemical composition constraints for next experiments)
- âœ… **Real GLENS data verification** (institutional validation)
- âœ… **Statistical significance** (p < 0.05, confidence â‰¥ 0.95)
- âœ… **Order-of-magnitude parameter checking** (physically realistic ranges)

### **Stage 2: Enhanced Researcher Generation (Only for Validated Experiments)**

```python
# If pre-validation passes, experiment goes to Researcher with enhancement
enhanced_context = {
    "validated_domain": "Chemical composition validation passed",
    "approved_datasets": ["GLENS", "ARISE-SAI"],
    "statistical_requirements": "p < 0.05, 20-member ensemble",
    "quality_guidelines": "Avoid plausibility traps, require empirical grounding"
}

# Researcher generates 128-page paper with validated context
# This produces higher quality papers because they're based on validated foundations
```

### **Stage 3: Final Quality Assurance**

```python
# Final verification ensures consistency between validation and generation
final_check = {
    "validation_consistency": "Ensured",
    "sakana_compliance": "Verified", 
    "quality_metrics": "Above threshold",
    "ready_for_publication": True
}
```

---

## ğŸ“Š **Results Analysis**

### **Processing Results:**

```python
if result['final_status'] == 'SUCCESS':
    print("âœ… Super paper generated successfully!")
    print(f"ğŸ“„ Paper: {result['generated_paper']}")
    print(f"â±ï¸  Time: {result['pipeline_duration']} seconds")
    print(f"ğŸ¯ Quality: {result['stage_results']['post_verification']['quality_metrics']}")
    
elif result['final_status'] == 'REJECTED_AT_PRE_SCREENING':
    print("âŒ Experiment rejected at pre-screening (saved time!)")
    print(f"ğŸ’¡ Issues: {result['stage_results']['pre_validation']['validation_details']['violations']}")
    print(f"â±ï¸  Time saved: ~300 seconds (avoided futile Researcher generation)")
    
else:
    print("ğŸ”„ Manual intervention required")
    print(f"ğŸ“‹ Report: {result['stage_results']}")
```

### **Efficiency Gains:**

```python
# Get pipeline statistics
stats = pipeline.get_pipeline_statistics()

print(f"ğŸ“ˆ Success rate: {stats['success_rate']:.1%}")
print(f"âš¡ Pre-screening efficiency: {stats['pre_screening_rejection_rate']:.1%}")
print(f"ğŸ’° Time saved: {stats['efficiency_improvement']}")
print(f"ğŸ¤– Automation effectiveness: {stats['automation_effectiveness']:.1%}")
```

---

## ğŸ›ï¸ **Configuration Options**

### **For Your Current Situation (Recommended):**

```python
from ai_researcher.pipeline.pipeline_config import RECOMMENDED_IMPROVED_CONFIG

# This configuration automates your manual correction workflow
config = RECOMMENDED_IMPROVED_CONFIG
# - Pre-validation gateway enabled
# - Synthetic data detection automated  
# - 3 automated correction cycles
# - Institutional validation required
# - Mac M3 optimized
```

### **Development/Testing:**

```python
from ai_researcher.pipeline.pipeline_config import DEVELOPMENT_CONFIG

# More lenient settings for experimentation
config = DEVELOPMENT_CONFIG
# - 5 correction cycles allowed
# - Intermediate results saved for debugging
# - Less strict validation for testing
```

### **Production Deployment:**

```python
from ai_researcher.pipeline.pipeline_config import PRODUCTION_CONFIG

# Optimized for production efficiency
config = PRODUCTION_CONFIG  
# - Strict validation enforced
# - Performance optimized
# - Minimal intermediate storage
```

---

## ğŸš€ **Quick Start Example**

### **Replace Your Current Manual Process:**

```python
# OLD WAY (Your current pain):
# 1. experiment â†’ researcher â†’ paper (128 pages, 5+ minutes)
# 2. paper â†’ sakana â†’ manual testing and corrections
# 3. repeat until it works (could be many cycles)

# NEW WAY (Automated):
from ai_researcher.pipeline import IntegrationPipeline

pipeline = IntegrationPipeline("/Users/apple/code/ai-s-plus/data/glens")

experiment = {
    "title": "SAI Chemical Composition Study",
    "parameters": {"h2so4_concentration_percent": 75.0, "temperature_k": 220.0}
}

# Single call handles everything automatically
result = pipeline.process_experiment(experiment)

# Either get a validated super-paper OR early rejection (saving time)
if result['final_status'] == 'SUCCESS':
    publish_paper(result['generated_paper'])  # Ready to go!
elif result['final_status'] == 'REJECTED_AT_PRE_SCREENING':
    fix_experiment(result['violations'])  # Clear guidance on what to fix
```

---

## ğŸ› ï¸ **Advanced Usage**

### **Custom Validation Rules:**

```python
# Add your own validation criteria
custom_validator = SakanaValidator(enforcement_level='strict')
custom_validator.validation_criteria.update({
    'custom_chemical_ranges': {'h2so4_concentration_percent': (60.0, 90.0)},  # Stricter composition ranges
    'required_ensemble_size': 30,   # Larger than standard 20
    'custom_confidence_level': 0.99 # Higher than standard 0.95
})

pipeline = IntegrationPipeline(
    glens_data_path="/path/to/data",
    custom_validator=custom_validator
)
```

### **Batch Processing:**

```python
# Process multiple experiments efficiently
experiments = [exp1, exp2, exp3, exp4, exp5]

results = []
for exp in experiments:
    result = pipeline.process_experiment(exp)
    results.append(result)
    
    # Pre-screening rejects bad experiments early (saves time)
    if result['final_status'] == 'REJECTED_AT_PRE_SCREENING':
        print(f"âŒ {exp['title']} rejected - saved 5+ minutes")
    elif result['final_status'] == 'SUCCESS':
        print(f"âœ… {exp['title']} - super paper generated!")

# Analyze batch results
successful = [r for r in results if r['final_status'] == 'SUCCESS']
print(f"ğŸ“Š Batch success rate: {len(successful)}/{len(experiments)}")
```

### **Integration with Your Existing Researcher System:**

```python
# Connect to your existing Researcher framework
pipeline = IntegrationPipeline(
    glens_data_path="/Users/apple/code/ai-s-plus/data/glens",
    researcher_config={
        "model_size": "12B",  # Your current Researcher model
        "api_endpoint": "http://localhost:8000/generate",
        "timeout": 600  # 10 minutes for complex papers
    }
)

# The pipeline will call your Researcher system automatically
# when experiments pass pre-validation
```

---

## ğŸ¯ **Key Benefits for Your Workflow**

1. **âš¡ Prevents Wasted Effort:** No more generating 128-page papers that fail validation
2. **ğŸ¤– Automates Manual Corrections:** Replaces your "test and change reports" workflow  
3. **ğŸ” Automated Synthetic Detection:** No more manual forensic data checking
4. **ğŸ“ˆ Higher Quality Papers:** Researcher gets validated input = better output
5. **ğŸ’° Time Savings:** Pre-screening rejects bad experiments in seconds vs. minutes
6. **ğŸ¯ Consistent Quality:** Sakana Principle enforcement prevents plausibility traps

**Bottom Line:** This transforms your manual, time-intensive correction process into an automated, efficient pipeline that produces higher quality results with less effort.

---

## ğŸ“ **Next Steps**

1. **Test the pipeline** with one of your existing experiments
2. **Compare time/quality** vs. your current manual process  
3. **Configure settings** for your specific workflow
4. **Integrate with existing Researcher** system
5. **Scale to batch processing** for multiple experiments

The pipeline is designed to seamlessly replace your current manual workflow while maintaining the high quality standards of the Sakana Principle.