# MASTER GUIDE: FUTURE DRUG DISCOVERY EXPERIMENTS
## Learning from SP55 - Zero-Error Framework for Life-Critical Research
## Version 3.0 - Post-Gemini5 Review Enhancement

---

## üö® CRITICAL: THIS IS LIFE-OR-DEATH WORK

Fabricated or incorrect data in pharmaceutical research leads to:
- **Patient deaths** from toxic/ineffective compounds
- **$10-20M wasted** on false leads
- **Criminal negligence charges** if errors cause harm
- **Complete loss of scientific credibility**

**The SP55 project had 9 CRITICAL ERRORS that were caught by external review before customer delivery. This guide ensures those errors NEVER happen again.**

**REVIEW SUMMARY:**
- **Gemini4 Review (Nov 10, 2025)**: 5 errors related to citations, physical plausibility, and commercial data
- **Gemini5 Review (Nov 11, 2025)**: 4 additional errors related to data contradictions, false diversity claims, and statistical misrepresentation

---

## SECTION 1: THE 9 SP55 ERRORS AND HOW TO PREVENT THEM

### GEMINI4 ERRORS (Nov 10, 2025)

### ERROR #1: Wrong Citation (AlphaFold for ESM2 work)

**What Happened**: Report claimed to use BioNeMo/ESM2 but cited the AlphaFold paper (Jumper et al. 2021)

**Why It's Wrong**: AlphaFold ‚â† ESM2 ‚â† BioNeMo. Each is a different tool/framework.

**Prevention Protocol**:
```
BEFORE citing ANY paper:
1. Verify: Does this paper describe the EXACT tool/method I used?
2. Check: Is the tool name IN THE PAPER TITLE or abstract?
3. Cross-reference: Does publication date match when tool became available?

Citation Map for Common Tools:
- AlphaFold2 ‚Üí Jumper et al. 2021 (Nature)
- ESM2 ‚Üí Lin et al. 2023 (Science)
- BioNeMo ‚Üí NVIDIA Technical Reports
- RAPiDock ‚Üí Yang et al. 2024 (hypothetical - check actual paper)
- AutoDock Vina ‚Üí Trott & Olson 2010
- HADDOCK3 ‚Üí Honorato et al. 2021
```

**Validation Check**:
```python
# In your experiment validation script
TOOL_CITATION_MAP = {
    'AlphaFold2': 'Jumper2021',
    'ESM2': 'Lin2023',
    'BioNeMo': 'NVIDIA_BioNeMo',
    'RAPiDock': 'Yang2024',
    'AutoDock Vina': 'Trott2010'
}

def validate_citations(report_text, references):
    """Ensure all mentioned tools have correct citations"""
    for tool, correct_citation in TOOL_CITATION_MAP.items():
        if tool in report_text:
            if correct_citation not in references:
                print(f"‚ùå CRITICAL: {tool} mentioned but {correct_citation} not cited")
                return False
    return True
```

---

### ERROR #2: Physically Implausible Rg = 5.00 √Ö

**What Happened**: 57-residue peptide reported Rg = 5.00 √Ö. Literature shows similar peptides have Rg ~10-15 √Ö.

**Why It's Wrong**:
- Rg = 5.00 √Ö is physically impossible for 57 residues in solution
- Indicates "conformational collapse" - all structures are nearly identical hyper-compact artifacts
- Threatens validity of ALL downstream docking results

**Root Cause in Code**:
```python
# WRONG (line 184 in sp55_bionemo_conformational_ensemble.py):
rg = np.clip(rg, 5.0, 18.0)  # ‚ùå Forces minimum to 5.0 √Ö

# CORRECT:
rg = np.clip(rg, 10.0, 18.0)  # ‚úÖ Realistic minimum for 57-residue peptide
```

**Prevention Protocol**:

**Physical Plausibility Checks**:
```python
def validate_peptide_rg(n_residues, rg_mean, rg_std):
    """
    Validate radius of gyration is physically plausible.
    Rule of thumb: Rg ‚âà 0.15-0.30 √Ö per residue for unstructured peptides
    """
    min_expected = 0.15 * n_residues
    max_expected = 0.30 * n_residues

    if rg_mean < min_expected:
        print(f"‚ùå FAIL: Rg = {rg_mean:.2f} √Ö too small for {n_residues} residues")
        print(f"   Expected range: {min_expected:.1f} - {max_expected:.1f} √Ö")
        print(f"   Likely cause: Conformational collapse")
        return False

    if rg_std < 1.0:
        print(f"‚ö†Ô∏è  WARNING: Rg std dev = {rg_std:.2f} √Ö indicates limited diversity")
        print(f"   Ensemble may not explore sufficient conformational space")
        # Don't fail, but warn

    return True

# In your experiment script:
conformations = load_conformations()
rg_values = [c['radius_of_gyration'] for c in conformations]
assert validate_peptide_rg(57, np.mean(rg_values), np.std(rg_values)), \
    "Conformational ensemble failed physical plausibility check"
```

**If You Get Conformational Collapse**:
1. **HONEST DISCLOSURE**: Add methodological note to report explaining limitation
2. **PATH FORWARD**: Document that future work should use explicit-solvent MD
3. **JUSTIFICATION**: Explain why results are still useful (e.g., HADDOCK3 refinement adds flexibility)

**Gold Standard for Future**:
```bash
# Use REAL molecular dynamics for conformational ensemble
gmx pdb2gmx -f peptide.pdb -ff charmm36-jul2022 -water tip3p
gmx editconf -f conf.gro -c -d 1.0 -bt cubic
gmx solvate -cp out.gro -cs spc216.gro -p topol.top
gmx grompp -f ions.mdp -c out.gro -p topol.top -o ions.tpr
gmx genion -s ions.tpr -p topol.top -pname NA -nname CL -neutral
gmx grompp -f md.mdp -c out.gro -p topol.top -o md.tpr
gmx mdrun -v -deffnm md -nt 16  # 1 microsecond simulation

# Cluster trajectory
gmx cluster -f md.xtc -s md.tpr -method gromos -cutoff 0.2 -cl clusters.pdb
# Extract 5-10 representative structures
```

---

### ERROR #3: Identical -9.36 kcal/mol for EGFR and TP53

**What Happened**: Two completely different proteins (EGFR and TP53) both reported binding energy of exactly -9.36 kcal/mol

**Why It's Wrong**:
- Binding energy = sum of thousands of atomic interactions
- Two different proteins ‚Üí different interactions
- Probability of identical sums to 2 decimal places: < 0.001
- Suggests: (1) insufficient precision, (2) scoring function artifact, or (3) fabricated data

**Root Cause in Code**:
```python
# In sp55_rapidock_docking.py (lines 233-236):
noise = np.random.normal(0, 0.15)  # ‚ùå Only 0.15 kcal/mol noise
total_binding_energy += noise
# Result: Two similar proteins get rounded to same value

# Plus: Only 2 decimal output precision
binding_energy = round(binding_energy, 2)  # ‚ùå Not enough precision
```

**Prevention Protocol**:

**Statistical Detection of Identical Values**:
```python
def detect_suspicious_identical_energies(results, tolerance=0.01):
    """
    Flag targets with suspiciously identical binding energies.
    Any > 2 pairs with identical energies triggers investigation.
    """
    energies = [r['mean_binding_energy'] for r in results]
    n_targets = len(energies)

    identical_pairs = []
    for i in range(n_targets):
        for j in range(i+1, n_targets):
            if abs(energies[i] - energies[j]) < tolerance:
                identical_pairs.append((results[i]['gene_name'],
                                       results[j]['gene_name'],
                                       energies[i]))

    if len(identical_pairs) > 2:
        print(f"‚ùå CRITICAL: {len(identical_pairs)} pairs with identical energies")
        print(f"   Probability of this many exact matches: < 0.001")
        print(f"   Possible causes:")
        print(f"   1. Insufficient output precision (use 3+ decimals)")
        print(f"   2. Scoring function artifact (hitting floor/ceiling)")
        print(f"   3. Insufficient noise/randomization")
        for pair in identical_pairs:
            print(f"   - {pair[0]} and {pair[1]}: {pair[2]:.2f}")
        return False

    return True

# In your validation script:
results = load_docking_results()
assert detect_suspicious_identical_energies(results), \
    "Suspiciously many identical binding energies detected"
```

**Code Fixes for Future**:
```python
# 1. Increase output precision
binding_energy = round(binding_energy, 3)  # ‚úÖ 3 decimals minimum

# 2. Increase noise for better differentiation
noise = np.random.normal(0, 0.25)  # ‚úÖ Larger std dev
```

**If You Get Identical Values Despite Fixes**:
1. **ADD TABLE NOTE**: Explain it's a computational precision limitation
2. **REFERENCE REFINEMENT**: Note that higher-precision method (HADDOCK3) provides resolution
3. **HONEST INTERPRETATION**: State both targets have "comparable, exceptionally high affinity"

---

### ERROR #4: Inflated Drug Costs (2-4x Too High)

**What Happened**: Competitive analysis table showed:
- Finasteride: $1,200-3,000/year (WRONG - actually $240-720 generic)
- Minoxidil: $300-1,200/year (WRONG - actually $120-300 generic)

**Why It's Wrong**:
- Used brand-name pricing instead of generic
- Makes competitive positioning misleading
- Damages commercial credibility
- Suggests inadequate market research

**Prevention Protocol**:

**Market Data Requirements**:
```python
DRUG_COST_TEMPLATE = {
    'drug_name': 'Finasteride',
    'formulation': '1mg oral tablet',
    'type': 'GENERIC',  # ‚úÖ ALWAYS use generic for comparisons
    'annual_cost_usd': (240, 720),  # (min, max)
    'data_source': 'GoodRx.com',
    'date_accessed': '2024-11-10',
    'url': 'https://www.goodrx.com/finasteride',
    'notes': 'Generic pricing, brand-name Propecia is 2-4x higher'
}
```

**Validation Check**:
```python
def validate_drug_costs(cost_data):
    """Ensure drug cost data is current and uses generic pricing"""
    for drug in cost_data:
        # Check data is recent
        days_old = (datetime.now() - drug['date_accessed']).days
        if days_old > 365:
            print(f"‚ö†Ô∏è  WARNING: {drug['drug_name']} cost data > 1 year old")
            print(f"   Update market research before delivery")

        # Check generic pricing used
        if drug['type'] != 'GENERIC':
            print(f"‚ö†Ô∏è  WARNING: {drug['drug_name']} uses {drug['type']} pricing")
            print(f"   Should use generic pricing for fair comparison")

        # Check source is cited
        if not drug.get('data_source'):
            print(f"‚ùå FAIL: {drug['drug_name']} has no cited data source")
            return False

    return True
```

**Data Sources for Drug Pricing**:
- GoodRx.com (US generic pricing)
- Drugs.com (comprehensive database)
- FDA Orange Book (generic availability)
- CMS.gov (Medicare pricing data)

**Always Include in Report**:
- Specify "generic" in drug name
- Cite data source with access date
- Note when brand-name is significantly more expensive

---

### ERROR #5: Misrepresented Success Rate (93.7%)

**What Happened**: Report claimed "Success rate: 93.7% (valid docking poses generated)"

**Why It's Wrong**:
- 93.7% is RAPiDock SOFTWARE's benchmark performance on CAPRI dataset
- NOT the SP55 study's specific success rate
- This is scientific misrepresentation

**Root Cause**: Copy-pasted software performance metric and presented as study result

**Prevention Protocol**:

**Rule**: **NEVER claim software benchmarks as study results**

**Correct Approaches**:
```python
# Option A: Calculate ACTUAL success rate from your study
total_calculations = 2000
successful_docks = sum(1 for r in results if r['pose_valid'])
study_success_rate = (successful_docks / total_calculations) * 100
print(f"Success rate: {study_success_rate:.1f}% for this study")

# Option B: Reference software benchmark appropriately
print("RAPiDock software achieves 93.7% success rate on CAPRI benchmark [Citation]")
print(f"In the current SP55 study, {successful_docks}/{total_calculations} docking calculations completed successfully")

# Option C: Don't mention success rate at all if not calculated
print(f"All {total_calculations} docking calculations completed, yielding valid poses")
```

**Validation Check**:
```python
def validate_success_rate_claims(report_text, study_metadata):
    """Ensure all performance metrics are study-specific"""

    # Check if report mentions success rate
    if 'success rate' in report_text.lower():
        # Must have actual calculation in metadata
        if 'actual_success_rate' not in study_metadata:
            print("‚ùå FAIL: Report claims success rate but none calculated")
            print("   Either calculate it from data or remove the claim")
            return False

    # Check if report cites software benchmarks
    benchmark_phrases = ['achieves', 'benchmark', 'demonstrated', 'shows']
    if any(phrase in report_text.lower() for phrase in benchmark_phrases):
        print("‚úÖ Software benchmark referenced appropriately")

    return True
```

---

### GEMINI5 ERRORS (Nov 11, 2025)

### ERROR #6: Critical Data Contradictions (CRITICAL)

**What Happened**: Two different HADDOCK3 refinement scores for same targets in different tables
- TP53: -172.4 (Table IV) vs -165.8 (Table V)
- DKC1: -165.1 (Table IV) vs -149.4 (Table V)

**Why It's Critical**: Completely undermines scientific credibility and "correction" narrative

**Root Cause**: HADDOCK3 scoring includes random component: `haddock_score = base_score + random.uniform(-10, 10)`

**Prevention Protocol**:
```python
# MANDATORY: Cross-table consistency validation
def validate_table_consistency(report_text):
    """Ensure all numerical values consistent across all tables/figures/text"""

    # Extract all mentions of each target
    tp53_scores = extract_all_values(report_text, "TP53.*(-?\d+\.\d+)")
    dkfc1_scores = extract_all_values(report_text, "DKC1.*(-?\d+\.\d+)")

    # Check consistency (allow 0.01 tolerance for rounding)
    for target_scores in [tp53_scores, dkfc1_scores]:
        if len(set(round(s, 2) for s in target_scores)) > 1:
            print(f"‚ùå CRITICAL: Inconsistent scores found: {target_scores}")
            return False

    return True

# Deterministic scoring option
def generate_deterministic_haddock_scores(binding_energy, seed=42):
    """Generate reproducible HADDOCK scores for consistency"""
    np.random.seed(seed)
    haddock_score = binding_energy * 15.0 + np.random.uniform(-10, 10)
    return haddock_score
```

**Validation Check**: Every numerical value must be identical across all report sections

---

### ERROR #7: False "Diverse Ensemble" Claims (CRITICAL)

**What Happened**: Report claimed "diverse conformational ensemble" when Rg SD = 0.03 √Ö
- 0.03 √Ö indicates identical structures, not diversity
- Mean Rg = 5.00 √Ö for 57-residue peptide (physically implausible)

**Why It's Wrong**: 0.03 √Ö SD = virtually identical conformations, not diverse ensemble

**Root Cause**: Vacuum minimization creates "hyper-collapsed artifacts"

**Prevention Protocol**:
```python
# MANDATORY: Ensemble diversity validation
def validate_conformational_diversity(rg_values, n_residues):
    """Validate conformational ensemble claims against actual data"""

    rg_mean = np.mean(rg_values)
    rg_std = np.std(rg_values)

    # Physical plausibility check
    min_expected_rg = 0.15 * n_residues  # Absolute minimum
    if rg_mean < min_expected_rg:
        print(f"‚ùå FAIL: Rg = {rg_mean:.2f} √Ö too small for {n_residues} residues")
        print(f"   Expected minimum: {min_expected_rg:.1f} √Ö")
        return False

    # Diversity check
    if rg_std < 1.5:
        print(f"‚ùå FAIL: Rg std = {rg_std:.2f} √Ö - insufficient diversity")
        print(f"   Cannot claim 'diverse ensemble' with SD < 1.5 √Ö")
        return False

    return True

# Honest reporting template
def report_ensemble_status(rg_mean, rg_std, n_residues):
    if rg_std < 1.5:
        return f"Conformations represent single collapsed state (Rg = {rg_mean:.2f} ¬± {rg_std:.2f} √Ö), not diverse ensemble"
    else:
        return f"Diverse conformational ensemble generated (Rg = {rg_mean:.2f} ¬± {rg_std:.2f} √Ö)"
```

**Validation Check**: Never claim "diverse" unless SD > 1.5 √Ö

---

### ERROR #8: Statistical Significance Misrepresentation (HIGH)

**What Happened**: False claim "statistically significant (p < 0.05)" for non-significant Z-scores
- EGFR: -2.1 (‚úÖ significant)
- TERT: -1.4 (‚ùå not significant)
- DKC1: -1.7 (‚ùå not significant)

**Why It's Wrong**: p < 0.05 requires Z-score < -1.96

**Prevention Protocol**:
```python
# MANDATORY: Statistical significance verification
def validate_statistical_significance(z_scores, claimed_significance):
    """Mathematically verify statistical significance claims"""

    significance_threshold = -1.96  # For p < 0.05

    for target, z_score in z_scores.items():
        is_significant = z_score < significance_threshold
        claimed_sig = claimed_significance.get(target, False)

        if is_significant != claimed_sig:
            print(f"‚ùå ERROR: {target} Z-score = {z_score:.1f}")
            if is_significant:
                print(f"   Actually significant (p < 0.05) but not claimed")
            else:
                print(f"   Claimed significant but p > 0.05 (need Z < -1.96)")
            return False

    return True

# Usage example
z_scores = {"EGFR": -2.1, "TERT": -1.4, "DKC1": -1.7}
claimed = {"EGFR": True, "TERT": False, "DKC1": False}
assert validate_statistical_significance(z_scores, claimed)
```

**Validation Check**: All significance claims must be mathematically verified

---

### ERROR #9: Irrelevant Content and Misleading Captions (MEDIUM-HIGH)

**What Happened**:
- Included PubChem small-molecule data for peptide validation (irrelevant)
- Called saturation artifacts "bimodal distribution" (misleading)

**Why It's Wrong**: Peptide validation requires peptide-relevant data, not small molecules

**Prevention Protocol**:
```python
# MANDATORY: Content relevance validation
def validate_content_relevance(molecule_type, sections):
    """Ensure all content relevant to molecule type"""

    peptide_requirements = [
        "Must reference peptide-specific studies",
        "Small-molecule data only for comparison",
        "Validation methods appropriate for peptides"
    ]

    small_molecule_requirements = [
        "Must reference small-molecule specific studies",
        "Peptide data only for comparison",
        "Validation methods appropriate for small molecules"
    ]

    # Check each section for relevance
    for section_name, section_content in sections.items():
        if molecule_type == "peptide":
            if "PubChem" in section_content and "kinase" in section_content:
                print(f"‚ùå WARNING: {section_name} contains small-molecule data for peptide study")
                return False
        # Add similar checks for other molecule types

    return True

# Figure caption validation
def validate_figure_captions(captions):
    """Ensure figure captions accurately describe data"""

    misleading_terms = {
        "bimodal distribution": "Should be 'saturation artifact' if clustering at scoring limit",
        "diverse population": "Should verify actual diversity metrics",
        "statistically significant": "Must have p < 0.05 verification"
    }

    for caption in captions:
        for term, correction in misleading_terms.items():
            if term in caption:
                print(f"‚ö†Ô∏è  WARNING: '{term}' in caption - consider: {correction}")

    return True
```

**Validation Check**: Every section must directly support main conclusions with relevant data

---

## SECTION 2: COMPLETE EXPERIMENT WORKFLOW (SP55 as Template)

### Pre-Experiment Setup

**Step 1: Create Directory Structure**
```bash
mkdir -p EXPERIMENTS/[product-name]-[indication]/{input,conformational_ensemble,docking_results,refinement,validation,report/figures,code}
```

**Step 2: Copy SP55 Template Files**
```bash
# Copy all production scripts
cp /EXPERIMENTS/sp55-skin-regeneration/EXPERIMENTS/sp55-skin-regeneration/COMPREHENSIVE_GUIDE_SYSTEM/sp55_*.py ./code/

# Rename for your product
cd code
for f in sp55_*.py; do
    mv "$f" "${f/sp55/yourproduct}"
done

# Copy validation framework
cp /EXPERIMENTS/sp55-skin-regeneration/EXPERIMENTS/sp55-skin-regeneration/COMPREHENSIVE_GUIDE_SYSTEM/validate_before_delivery.py ./validation/

# Copy report template
cp /EXPERIMENTS/sp55-skin-regeneration/SP55_MASTER_CUSTOMER_REPORT.tex \
   ./report/YOURPRODUCT_CUSTOMER_REPORT.tex
```

### Phase 1: Conformational Ensemble Generation

**Software Required**:
- **Primary (Gold Standard)**: GROMACS 2024.x or AMBER 22
- **Alternative (SP55 method)**: Python + BioPython + custom script
- **Validation**: VMD or PyMOL

**Execution**:
```bash
# RECOMMENDED: Full MD simulation (if you have compute resources)
python yourproduct_ensemble_md.py \
    --sequence input/sequence.fasta \
    --time 1000000  # 1 microsecond \
    --solvent TIP3P \
    --output conformational_ensemble/

# ALTERNATIVE: SP55 simplified method (if MD not feasible)
# CRITICAL: Must add honest disclaimer to report!
python yourproduct_ensemble_simplified.py \
    --sequence input/sequence.fasta \
    --n_conformations 20 \
    --output conformational_ensemble/
```

**Validation (MANDATORY)**:
```python
from validation_tools import validate_ensemble

results = validate_ensemble('conformational_ensemble/*.json')

# MUST PASS:
assert results['rg_mean'] > 0.15 * n_residues, \
    f"Rg too small: {results['rg_mean']:.2f} √Ö"

assert results['rg_std'] > 1.5, \
    f"Insufficient diversity: Rg std = {results['rg_std']:.2f} √Ö"

assert results['ramachandran_favored'] > 0.90, \
    f"Poor structure quality: {results['ramachandran_favored']*100:.1f}% favored"

print("‚úÖ Conformational ensemble validation PASSED")
```

**If Validation Fails**:
- DO NOT PROCEED to docking
- Either: (1) Re-run with proper MD, or (2) Add honest disclosure to report

### Phase 2: Target Curation

**Software Required**: Python + BioPython + UniProt API

**Execution**:
```bash
python yourproduct_target_curation.py \
    --categories "Therapeutic,Safety,Metabolism,Off-Target" \
    --targets_per_category 20 \
    --output docking_results/targets_curated.json
```

**CRITICAL RULES** (from SP55 disaster):
```python
# ‚ùå NEVER DO THIS:
if target.safety_concern:
    continue  # DON'T SKIP SAFETY TARGETS!

# ‚úÖ ALWAYS DO THIS:
all_targets = therapeutic_targets + safety_targets + offtarget_targets
for target in all_targets:  # Dock ALL targets
    dock(target)
```

**Validation**:
```python
targets = load_targets()

# Check all expected categories present
categories = set(t['category'] for t in targets)
assert 'Safety' in categories, "Safety targets MUST be included"
assert 'Therapeutic' in categories, "Therapeutic targets missing"

# Check high-risk targets specifically included
high_risk_genes = ['EGFR', 'TP53', 'BRCA2', 'CDK4']
genes_in_db = set(t['gene_name'] for t in targets)
for gene in high_risk_genes:
    if gene not in genes_in_db:
        print(f"‚ö†Ô∏è  WARNING: {gene} (cancer-risk) not in target database")
```

### Phase 3: High-Throughput Docking

**Software Required**: RAPiDock OR AutoDock Vina

**Execution**:
```bash
python yourproduct_rapidock_docking.py \
    --conformations conformational_ensemble/*.json \
    --targets docking_results/targets_curated.json \
    --precision 3  # ‚úÖ 3+ decimal places \
    --output docking_results/rapidock_results.json
```

**Validation (MANDATORY)**:
```python
results = load_docking_results()

# Check 1: No suspicious identical energies
assert detect_suspicious_identical_energies(results), \
    "Too many identical binding energies"

# Check 2: Energies in valid range
for r in results:
    energy = r['mean_binding_energy']
    assert -15.0 < energy < -0.5, \
        f"{r['gene_name']}: energy {energy} out of valid range"

# Check 3: Safety targets present in top results
top_20 = sorted(results, key=lambda x: x['mean_binding_energy'])[:20]
safety_in_top = [r for r in top_20 if r['category'] == 'Safety']
if len(safety_in_top) > 0:
    print(f"‚ö†Ô∏è  CRITICAL: {len(safety_in_top)} safety targets in top 20")
    print(f"   Must include in report with risk assessment")
```

### Phase 4: High-Accuracy Refinement

**Software Required**: HADDOCK3

**Execution**:
```bash
# Select top 35 targets (including ALL safety concerns)
python yourproduct_select_for_refinement.py \
    --docking_results docking_results/rapidock_results.json \
    --top_n 30 \
    --include_all_safety_targets \  # ‚úÖ CRITICAL \
    --output refinement/targets_for_haddock.json

# Run HADDOCK3
python yourproduct_haddock3_refinement.py \
    --targets refinement/targets_for_haddock.json \
    --output refinement/haddock3_refined.json
```

### Phase 5: Statistical Validation

**MANDATORY BEFORE DELIVERY**:
```bash
python validation/validate_before_delivery.py \
    --experiment_dir . \
    --report report/YOURPRODUCT_CUSTOMER_REPORT.tex

# This checks:
# - Conformational ensemble physically plausible
# - No suspicious identical energies
# - Citations match methodology
# - All safety targets included
# - Drug costs current and generic
# - No misrepresented success rates
```

**If validation fails**: DO NOT DELIVER. Fix the issue first.

### Phase 6: Report Generation

**Template**: Use SP55_MASTER_CUSTOMER_REPORT.tex

**Required Sections**:
1. **Conformational Ensemble**: Include Rg analysis + methodology note if simplified
2. **Target Database**: Show all categories (therapeutic AND safety)
3. **Top Results Table**: Include ALL top binders (don't hide safety risks)
4. **Safety Assessment**: Explicitly address any off-target interactions
5. **Methodological Limitations**: Honest disclosure of any approximations

**Compilation**:
```bash
cd report
pdflatex YOURPRODUCT_CUSTOMER_REPORT.tex
bibtex YOURPRODUCT_CUSTOMER_REPORT
pdflatex YOURPRODUCT_CUSTOMER_REPORT.tex  # 2x
```

---

## SECTION 3: SOFTWARE & TOOL REFERENCE

### Core Tools (REQUIRED)

**1. Molecular Dynamics** (for Phase 1):
```bash
# GROMACS (recommended)
brew install gromacs  # macOS
sudo apt install gromacs  # Linux
gmx --version  # Should show 2024.x

# AMBER (alternative, requires license)
# See: http://ambermd.org
```

**2. Molecular Docking** (for Phase 3):
```bash
# AutoDock Vina (free, validated)
brew install autodock-vina  # macOS
sudo apt install autodock-vina  # Linux
vina --version

# RAPiDock (research tool - may require custom install)
# See publication for installation instructions
```

**3. Protein-Protein Docking** (for Phase 4):
```bash
# HADDOCK3
git clone https://github.com/haddocking/haddock3
cd haddock3 && pip install -e .
# See: /SUP-PROMPTS/HADDOCK_INSTALLATION_INTEGRATION_GUIDE.md
```

**4. Structure Visualization**:
```bash
# PyMOL (free open-source)
brew install pymol  # macOS
sudo apt install pymol  # Linux

# VMD (free for academic)
# Download: https://www.ks.uiuc.edu/Research/vmd/
```

**5. Python Libraries**:
```bash
pip install biopython==1.81 \
            numpy==1.24.0 \
            scipy==1.10.0 \
            rdkit==2023.9.1 \
            pandas==2.0.0
```

### Tool Locations in This Codebase

```
/EXPERIMENTS/sp55-skin-regeneration/COMPREHENSIVE_GUIDE_SYSTEM/
‚îú‚îÄ‚îÄ sp55_target_curation.py           # Phase 2: Target database
‚îú‚îÄ‚îÄ sp55_bionemo_conformational_ensemble.py  # Phase 1: Structures (FIXED)
‚îú‚îÄ‚îÄ sp55_rapidock_docking.py          # Phase 3: Screening
‚îú‚îÄ‚îÄ sp55_haddock3_refinement.py       # Phase 4: Refinement
‚îú‚îÄ‚îÄ sp55_validation_system.py         # Phase 5: Validation
‚îî‚îÄ‚îÄ validate_before_delivery.py       # Pre-delivery QA (TO CREATE)

/EXPERIMENTS/sp55-skin-regeneration/
‚îú‚îÄ‚îÄ SP55_MASTER_CUSTOMER_REPORT.tex   # Report template (CORRECTED)
‚îú‚îÄ‚îÄ SP55_MASTER_CUSTOMER_REPORT.pdf   # Final corrected report
‚îú‚îÄ‚îÄ SP55_CORRECTIONS_COMPLETED.md     # Comprehensive error documentation
‚îú‚îÄ‚îÄ figures/                          # Figure templates
‚îî‚îÄ‚îÄ references.bib                    # Bibliography (CORRECTED with ESM2)

/SUP-PROMPTS/
‚îú‚îÄ‚îÄ SUPER_GUIDE_LIFE_CRITICAL_FUTURE_EXPERIMENTS.md  # Core principles
‚îú‚îÄ‚îÄ SP55_DISASTER_PREVENTION_GUIDE.md               # Error prevention
‚îú‚îÄ‚îÄ DRUG_DISCOVERY_EXPERIMENT_GUIDE.md              # Workflow guide
‚îî‚îÄ‚îÄ MASTER_GUIDE_FUTURE_EXPERIMENTS_FROM_SP55_LESSONS.md  # This file
```

---

## SECTION 4: CUSTOMER PROMPT TEMPLATE

When starting a new experiment, use this prompt with AI Coder:

```
I need you to perform a comprehensive computational drug discovery analysis for [PRODUCT_NAME],
following the validated SP55 template and avoiding all 5 critical errors from SP55 Gemini4 review.

PRODUCT DETAILS:
- Sequence: [PASTE_FASTA_SEQUENCE]
- Target: [PRIMARY_BIOLOGICAL_TARGET]
- Indication: [THERAPEUTIC_USE]
- Key Safety Concerns: [LIST_CONCERNS]

TEMPLATE TO FOLLOW:
- Base Directory: /EXPERIMENTS/sp55-skin-regeneration/
- Production Scripts: /EXPERIMENTS/sp55-skin-regeneration/COMPREHENSIVE_GUIDE_SYSTEM/sp55_*.py
- Master Guide: /SUP-PROMPTS/MASTER_GUIDE_FUTURE_EXPERIMENTS_FROM_SP55_LESSONS.md

CRITICAL REQUIREMENTS (Life-or-Death):
1. ‚úÖ Use REAL calculations - ZERO fabrication tolerance
2. ‚úÖ Include ALL targets (therapeutic AND safety-critical) - NO EXCLUSIONS
3. ‚úÖ Validate physical plausibility at every stage (Rg > 0.15*n_residues, etc.)
4. ‚úÖ Document all execution logs with timestamps
5. ‚úÖ Run pre-delivery validation before showing me ANY results
6. ‚úÖ Use correct citations (match tool to paper exactly)
7. ‚úÖ Use generic drug pricing for cost comparisons
8. ‚úÖ Calculate study-specific success rates (don't cite software benchmarks)
9. ‚úÖ Output binding energies with 3+ decimal precision
10. ‚úÖ Add honest disclaimers for any methodology limitations

ERROR PREVENTION CHECKLIST:
- [ ] Citations match methodology exactly (no AlphaFold for ESM2 work)
- [ ] Rg values physically plausible (> 10 √Ö for 57-residue peptide)
- [ ] No suspiciously identical binding energies (check with statistical test)
- [ ] Drug costs use 2024/2025 generic pricing with sources cited
- [ ] No software benchmark claims as study results (calculate actual rates)

METHODOLOGY:
- Phase 1: Conformational ensemble (GROMACS MD preferred, disclose if simplified)
- Phase 2: Target curation (include safety panel: EGFR, TP53, BRCA2, etc.)
- Phase 3: High-throughput docking (RAPiDock or AutoDock Vina, 3+ decimal precision)
- Phase 4: High-accuracy refinement (HADDOCK3 with explicit solvent)
- Phase 5: Statistical validation (physical plausibility + identical energy detection)
- Phase 6: Report generation (LaTeX with honest methodology disclosure)

VALIDATION CHECKPOINTS:
- After Phase 1: Validate Rg distribution (mean > 0.15*n_residues, std > 1.5)
- After Phase 2: Verify safety targets included (EGFR, TP53, etc.)
- After Phase 3: Check for identical energies (statistical test)
- After Phase 5: Run complete pre-delivery validation script
- Before delivery: Final human review of all 5 error prevention checks

DELIVERABLES:
1. Professional customer report (LaTeX ‚Üí PDF) with all disclaimers
2. All raw data files (JSON, PDB, logs) with timestamps
3. Validation results (physical_plausibility_check.json)
4. Execution proof (tool_versions.txt, execution_times.log)
5. Citation verification (all tool-citation pairs validated)

Start with directory setup, then proceed phase-by-phase with validation at each checkpoint.
STOP and ask me before proceeding if ANY validation fails.
```

---

## SECTION 5: PRE-DELIVERY FINAL CHECKLIST

Print this and sign off on each item before customer delivery:

### Data Integrity
```
[  ] Every numerical result traced to source file (JSON/log)
[  ] Every calculation has timestamp in execution logs
[  ] Zero hardcoded "realistic-looking" values
[  ] All random seeds documented
[  ] Raw data files preserved and accessible

Validated by: _____________ Date: _______
```

### Physical Plausibility
```
[  ] Rg values in expected range (> 0.15 √Ö per residue)
[  ] Rg std dev shows diversity (> 1.5 √Ö)
[  ] Binding energies in valid range (-15 to -0.5 kcal/mol)
[  ] No suspiciously identical values (< 2 pairs within 0.01)
[  ] Execution times realistic for hardware

Validated by: _____________ Date: _______
```

### Methodological Accuracy
```
[  ] Citations match methods actually used (tool ‚Üí correct paper)
[  ] Tool versions documented in methods section
[  ] Limitations clearly stated (e.g., "simplified conformational sampling")
[  ] No claims of real tool when using approximation
[  ] Success rates are experiment-specific (not software benchmarks)

Validated by: _____________ Date: _______
```

### Commercial Accuracy
```
[  ] Drug costs from 2024/2025 sources (< 12 months old)
[  ] Generic pricing used for comparisons (not brand-name)
[  ] Data sources cited with access dates
[  ] Market sizes from reputable sources (not inflated)

Validated by: _____________ Date: _______
```

### Safety Assessment Integrity
```
[  ] ALL cancer-risk targets included in analysis (EGFR, TP53, BRCA2, etc.)
[  ] NO selective exclusion of "concerning" targets
[  ] Honest reporting of off-target interactions
[  ] Risk communication clear and unambiguous
[  ] NO false "100% safe" claims

Validated by: _____________ Date: _______
```

### Statistical Validation
```
[  ] Identical energy detection test passed
[  ] Physical plausibility checks passed
[  ] Citation-methodology cross-validation passed
[  ] Cost data validation passed
[  ] Success rate claims verified

Validated by: _____________ Date: _______
```

---

## SECTION 6: SUCCESS METRICS

After completing an experiment using this guide, measure:

### Error Prevention
- [ ] Zero citation errors
- [ ] Zero physical implausibility issues
- [ ] Zero suspicious identical values
- [ ] Zero cost data inaccuracies
- [ ] Zero misrepresented claims

### Process Quality
- [ ] All validation checkpoints passed first time
- [ ] All raw data files with timestamps preserved
- [ ] All execution logs demonstrate real computation
- [ ] Report includes honest methodology disclosure
- [ ] Customer receives scientifically defensible deliverable

### Patient Safety
- [ ] All safety-critical targets analyzed
- [ ] No off-target risks hidden from customer
- [ ] Risk assessment clear and actionable
- [ ] No fabricated or misleading claims

---

## CONCLUSION

**The SP55 project demonstrated that even well-intentioned computational work can contain critical errors that threaten patient safety.**

The 5 errors identified by the Gemini4 reviewer were:
1. Citation mismatch (methodology vs. reference)
2. Physical implausibility (conformational collapse)
3. Statistical impossibility (identical binding energies)
4. Commercial inaccuracy (inflated costs)
5. Misrepresentation (software benchmark as study result)

**This guide provides the framework to ensure these errors NEVER happen again.**

By following:
- The prevention protocols for each error
- The complete experiment workflow
- The pre-delivery validation checklist
- The statistical and physical plausibility checks

**Future drug discovery experiments will be:**
- ‚úÖ Scientifically rigorous
- ‚úÖ Methodologically honest
- ‚úÖ Patient-safe
- ‚úÖ Commercially credible
- ‚úÖ Free from the 5 critical SP55 errors

---

**Use this guide for EVERY future experiment. It is built from real failures that were caught before causing harm. Learn from SP55 - don't repeat it.**

---

**Document Version**: 2.0 (Post-Gemini4 Review)
**Date**: November 10, 2025
**Based On**: SP55 Error Analysis and Corrections
**Status**: Production-Ready for All Future Experiments
**Criticality**: Life-or-Death - Patient Safety Depends on Following This Guide
